{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "JGkYOtJw4Kn2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/HAPPYSAD'\n",
        "\n",
        "image_size = (128, 128)\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "P8Mu0D9a42ct"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "dALJ25os6s0Z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=f'{dataset_path}/train',\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-hLt7-R7Ejw",
        "outputId": "c2a598fa-32d1-4023-e5e1-558068425b62"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 555 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_generator = val_datagen.flow_from_directory(\n",
        "    directory = f'{dataset_path}/valid',\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode ='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OglKPzo9GlFc",
        "outputId": "d1977993-620b-4183-d120-1f70f97ed308"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 53 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    directory = f'{dataset_path}/valid',\n",
        "    target_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary',\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrbbipRJHn6P",
        "outputId": "64d264d9-1839-409f-a4cb-cf703b44e3b3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 53 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "mYcIIPE7IT-Z"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "LLyQNq3wJdyw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data = val_generator,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR19iymnMW2E",
        "outputId": "0ff272e3-1cb6-43b0-81bd-e30329b1aa2d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9842 - loss: 0.0434 - val_accuracy: 0.9434 - val_loss: 0.2211\n",
            "Epoch 2/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9868 - loss: 0.0281 - val_accuracy: 0.9057 - val_loss: 0.4252\n",
            "Epoch 3/20\n",
            "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9891 - loss: 0.0280 - val_accuracy: 0.9434 - val_loss: 0.2504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYk55-zEO_Tq",
        "outputId": "6313a62b-9b89-408b-c92b-0e77d79cf7d8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9623 - loss: 0.1629\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.22114624083042145, 0.9433962106704712]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "img_path = \"/content/deneme foto.jpg\"\n",
        "img = image.load_img(img_path, target_size=(128, 128))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = img_array / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "if prediction[0][0] > 0.5:\n",
        "    print(\"SadğŸ˜¢\")\n",
        "else:\n",
        "    print(\"HappyğŸ™‚\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMKyiY4ZPsWC",
        "outputId": "9ecba018-51b1-4306-ccc7-aae93e8cb38c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "HappyğŸ™‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"happysad_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXxG00Z5RL8l",
        "outputId": "bfb2ddec-e0eb-40f7-dd80-c7e66796a438"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ]
}